{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c78d51e-8eca-455b-8e3f-88da22bf7534",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44056904-7f92-4494-899e-bec72ae7b56d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/cluster/project/treutlein/jjans/software/miniforge3/envs/chrombpnet2/bin:/cluster/apps/lsf/10.1/linux2.6-glibc2.3-x86_64/bin:/cluster/apps/lsf/10.1/linux2.6-glibc2.3-x86_64/bin:/cluster/apps/gcc-8.2.0/cuda-12.1.1-mpwcqkwqghc7y2at5a6wuuhbgmm6efux/bin:/cluster/apps/gcc-8.2.0/openblas-0.3.15-huwxbhezdzoo74awrgoz6sd2qndpmdva/bin:/cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/bin:/cluster/apps/gcc-8.2.0/eccodes-2.21.0-o4xitaateyj4fuopb6chuxme7d5bp4zp/bin:/cluster/apps/gcc-8.2.0/hdf5-1.10.1-qj3ju3qfhvucsk5eevrtb2lehbux5nmv/bin:/cluster/apps/nss/jupyterhub/3.5.1/bin:/cluster/apps/gcc-8.2.0/git-2.31.1-q45wg6avfyvko4weuhmnpghaag45ynoo/bin:/cluster/apps/gcc-8.2.0/npm-6.14.9-774crfohwvu6a33ijcow7x5cvonu44oi/bin:/cluster/apps/gcc-8.2.0/r-4.2.2-ydfaklhfrhw5dy6qcfzxlxfviwovcord/bin:/cluster/spack/apps/linux-centos7-x86_64/gcc-4.8.5/gcc-8.2.0-6xqov2fhvbmehix42slain67vprec3fs/bin:/cluster/apps/local:/cluster/apps/sfos/bin:/usr/local/bin:/usr/local/sbin:/usr/sbin:/usr/bin:/sbin:/bin:/cluster/slurm/apps/bin:/cluster/apps/local:/cluster/apps/local'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "811e9975-22b7-4baf-b2b7-c59272e8a310",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/cluster/project/treutlein/jjans/software/miniforge3/envs/cuda11_env/lib:/cluster/project/treutlein/jjans/software/miniforge3/envs/chrompbnet2/lib:/cluster/project/treutlein/jjans/software/miniforge3/envs/chrompbnet/lib:/cluster/apps/lsf/10.1/linux2.6-glibc2.3-x86_64/lib:/cluster/apps/lsf/10.1/linux2.6-glibc2.3-x86_64/lib:/cluster/apps/gcc-8.2.0/cudnn-8.9.2.26-ogi7ed2h6ejs7vumekv46idqqas4axgq/lib:/cluster/apps/gcc-8.2.0/cuda-12.1.1-mpwcqkwqghc7y2at5a6wuuhbgmm6efux/lib64:/cluster/apps/gcc-8.2.0/nccl-2.11.4-1-pwkiz23vbeac3vt5ykybdwzaykprizb2/lib:/cluster/apps/gcc-8.2.0/openblas-0.3.15-huwxbhezdzoo74awrgoz6sd2qndpmdva/lib:/cluster/apps/nss/gcc-8.2.0/python/3.10.4/x86_64/lib64:/cluster/apps/gcc-8.2.0/zlib-1.2.9-roj3c3p7lbd2kn3gstlt4rxdcgvb3csi/lib:/cluster/apps/gcc-8.2.0/eccodes-2.21.0-o4xitaateyj4fuopb6chuxme7d5bp4zp/lib64:/cluster/apps/gcc-8.2.0/hdf5-1.10.1-qj3ju3qfhvucsk5eevrtb2lehbux5nmv/lib:/cluster/apps/gcc-8.2.0/npm-6.14.9-774crfohwvu6a33ijcow7x5cvonu44oi/lib:/cluster/apps/gcc-8.2.0/r-4.2.2-ydfaklhfrhw5dy6qcfzxlxfviwovcord/rlib/R/lib:/cluster/spack/apps/linux-centos7-x86_64/gcc-4.8.5/gcc-8.2.0-6xqov2fhvbmehix42slain67vprec3fs/lib64:/cluster/spack/apps/linux-centos7-x86_64/gcc-4.8.5/gcc-8.2.0-6xqov2fhvbmehix42slain67vprec3fs/lib:/cluster/apps/lsf/10.1/linux2.6-glibc2.3-x86_64/lib::'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"LD_LIBRARY_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07001e56-5ed2-4411-a1d4-5e5131ffe2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from chrombpnet-lite\n",
    "\n",
    "import deepdish as dd\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import shap\n",
    "import pyfaidx\n",
    "import shutil\n",
    "import errno\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9483cde-074b-4c6e-b534-e8bd8a833a6b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import chrombpnet.evaluation.interpret.shap_utils as shap_utils\n",
    "import chrombpnet.evaluation.interpret.input_utils as input_utils\n",
    "\n",
    "NARROWPEAK_SCHEMA = [\"chr\", \"start\", \"end\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"summit\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20190b77-adc0-49fa-bd6d-6c18198a7db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable eager execution so shap deep explainer wont break\n",
    "tf.compat.v1.disable_eager_execution()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79f0e3b9-22cc-4fb7-8e74-57e69733dbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_interpret_args():\n",
    "    parser = argparse.ArgumentParser(description=\"get sequence contribution scores for the model\")\n",
    "    parser.add_argument(\"-g\", \"--genome\", type=str, required=True, help=\"Genome fasta\")\n",
    "    parser.add_argument(\"-r\", \"--regions\", type=str, required=True, help=\"10 column bed file of peaks. Sequences and labels will be extracted centered at start (2nd col) + summit (10th col).\")\n",
    "    parser.add_argument(\"-m\", \"--model_h5\", type=str, required=True, help=\"Path to trained model, can be both bias or chrombpnet model\")\n",
    "    parser.add_argument(\"-o\", \"--output-prefix\", type=str, required=True, help=\"Output prefix\")\n",
    "    parser.add_argument(\"-d\", \"--debug_chr\", nargs=\"+\", type=str, default=None, help=\"Run for specific chromosomes only (e.g. chr1 chr2) for debugging\")\n",
    "    parser.add_argument(\"-p\", \"--profile_or_counts\", nargs=\"+\", type=str, default=[\"counts\", \"profile\"], choices=[\"counts\", \"profile\"],\n",
    "                        help=\"use either counts or profile or both for running shap\")\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    return args\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "146d491c-e631-43f3-917c-93eab91d2b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_shap_dict(seqs, scores):\n",
    "    assert(seqs.shape==scores.shape)\n",
    "    assert(seqs.shape[2]==4)\n",
    "\n",
    "    # construct a dictionary for the raw shap scores and the\n",
    "    # the projected shap scores\n",
    "    # MODISCO workflow expects one hot sequences with shape (None,4,inputlen)\n",
    "    d = {\n",
    "            'raw': {'seq': np.transpose(seqs, (0, 2, 1)).astype(np.int8)},\n",
    "            'shap': {'seq': np.transpose(scores, (0, 2, 1)).astype(np.float16)},\n",
    "            'projected_shap': {'seq': np.transpose(seqs*scores, (0, 2, 1)).astype(np.float16)}\n",
    "        }\n",
    "\n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40786542-7abc-4f23-950a-08c168b03c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpret(model, seqs, output_prefix, profile_or_counts,save_files=True):\n",
    "    print(\"Seqs dimension : {}\".format(seqs.shape))\n",
    "\n",
    "    outlen = model.output_shape[0][1]\n",
    "\n",
    "    profile_model_input = model.input\n",
    "    profile_input = seqs\n",
    "    counts_model_input = model.input\n",
    "    counts_input = seqs\n",
    "\n",
    "    if \"counts\" in profile_or_counts:\n",
    "        profile_model_counts_explainer = shap.explainers.deep.TFDeepExplainer(\n",
    "            (counts_model_input, tf.reduce_sum(model.outputs[1], axis=-1)),\n",
    "            shap_utils.shuffle_several_times,\n",
    "            combine_mult_and_diffref=shap_utils.combine_mult_and_diffref)\n",
    "\n",
    "        print(\"Generating 'counts' shap scores\")\n",
    "        counts_shap_scores = profile_model_counts_explainer.shap_values(\n",
    "            counts_input, progress_message=100)\n",
    "\n",
    "        counts_scores_dict = generate_shap_dict(seqs, counts_shap_scores)\n",
    "\n",
    "        if save_files:\n",
    "            # save the dictionary in HDF5 formnat\n",
    "            print(\"Saving 'counts' scores\")\n",
    "\n",
    "            dd.io.save(\"{}.counts_scores.h5\".format(output_prefix),\n",
    "                        counts_scores_dict,\n",
    "                        compression='blosc')\n",
    "\n",
    "#            del counts_shap_scores, counts_scores_dict\n",
    "\n",
    "    if \"profile\" in profile_or_counts:\n",
    "        weightedsum_meannormed_logits = shap_utils.get_weightedsum_meannormed_logits(model)\n",
    "        profile_model_profile_explainer = shap.explainers.deep.TFDeepExplainer(\n",
    "            (profile_model_input, weightedsum_meannormed_logits),\n",
    "            shap_utils.shuffle_several_times,\n",
    "            combine_mult_and_diffref=shap_utils.combine_mult_and_diffref)\n",
    "\n",
    "        print(\"Generating 'profile' shap scores\")\n",
    "        profile_shap_scores = profile_model_profile_explainer.shap_values(\n",
    "            profile_input, progress_message=100)\n",
    "\n",
    "        profile_scores_dict = generate_shap_dict(seqs, profile_shap_scores)\n",
    "\n",
    "        if save_files:\n",
    "            # save the dictionary in HDF5 formnat\n",
    "            print(\"Saving 'profile' scores\")\n",
    "            dd.io.save(\"{}.profile_scores.h5\".format(output_prefix),\n",
    "                        profile_scores_dict,\n",
    "                        compression='blosc')\n",
    "    \n",
    "    results = {}\n",
    "    results['profile'] = ''\n",
    "    results['counts_scores'] = ''\n",
    "    results['counts_shap'] = ''\n",
    "    if \"profile\" in profile_or_counts:\n",
    "        results['profile'] = profile_scores_dict\n",
    "    if \"counts\" in profile_or_counts:\n",
    "        results['counts_scores'] = counts_scores_dict\n",
    "        results['counts_shap'] = counts_shap_scores\n",
    "\n",
    "    return(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7f1bd2a-31a1-40dd-8268-cad15980d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "NARROWPEAK_SCHEMA = [\"chr\", \"start\", \"end\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"summit\"]\n",
    "\n",
    "regions_df = pd.read_csv(\"regions_of_interest/IGFBP2_regions_peaks_human.bed\", sep='\\t', names=NARROWPEAK_SCHEMA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ae034e25-4c5e-47e7-82db-11accca3c855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>summit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chr2</td>\n",
       "      <td>216636508</td>\n",
       "      <td>216637488</td>\n",
       "      <td>human_peaks_peak_48293</td>\n",
       "      <td>380</td>\n",
       "      <td>.</td>\n",
       "      <td>5.29416</td>\n",
       "      <td>40.7695</td>\n",
       "      <td>38.0041</td>\n",
       "      <td>799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chr      start        end                       1    2  3        4  \\\n",
       "0  chr2  216636508  216637488  human_peaks_peak_48293  380  .  5.29416   \n",
       "\n",
       "         5        6  summit  \n",
       "0  40.7695  38.0041     799  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regions_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1df9be3f-a1fa-40b5-9c92-5a00a2da1659",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import chrombpnet.training.utils.losses as losses\n",
    "from chrombpnet.training.utils.data_utils import one_hot\n",
    "from tensorflow.keras.utils import get_custom_objects\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "def get_seq(peaks_df, genome, width):\n",
    "    \"\"\"\n",
    "    Same as get_cts, but fetches sequence from a given genome.\n",
    "    \"\"\"\n",
    "    vals = []\n",
    "    peaks_used = []\n",
    "    for i, r in peaks_df.iterrows():\n",
    "        sequence = str(genome[r['chr']][(r['start']+r['summit'] - width//2):(r['start'] + r['summit'] + width//2)])\n",
    "        if len(sequence) == width:\n",
    "            vals.append(sequence)\n",
    "            peaks_used.append(True)\n",
    "        else:\n",
    "            peaks_used.append(False)\n",
    "\n",
    "    return one_hot.dna_to_one_hot(vals), np.array(peaks_used)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "04da25d9-e38b-4361-93b4-1374846c47f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "got the model\n",
      "got the model\n",
      "got the model\n",
      "got the model\n",
      "got the model\n"
     ]
    }
   ],
   "source": [
    "for fold in ['fold_0','fold_1','fold_2','fold_3','fold_4']:\n",
    "    \n",
    "    model_path = 'celltype_models_human/modelv1_enterocytes/'+fold+'/output/models/chrombpnet_nobias.h5'\n",
    "    \n",
    "    custom_objects={\"multinomial_nll\": losses.multinomial_nll, \"tf\": tf}    \n",
    "    get_custom_objects().update(custom_objects)    \n",
    "    model=load_model(model_path,compile=False)\n",
    "    print(\"got the model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d22ce539-5137-44ee-8799-42ff5d2619cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inferred model inputlen:  2114\n"
     ]
    }
   ],
   "source": [
    "# infer input length\n",
    "inputlen = model.input_shape[1] # if bias model (1 input only)\n",
    "print(\"inferred model inputlen: \", inputlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b99b83ce-736f-422c-aaa9-ff151e562a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_path = 'encode_data/hg38.fa'\n",
    "region_index = 0\n",
    "#region 0 contains the human chimp divergent SNCs\n",
    "\n",
    "import pyfaidx\n",
    "genome_path = 'encode_data/hg38.fa'\n",
    "genome = pyfaidx.Fasta(genome_path)\n",
    "width = input_len = inputlen\n",
    "chrom=regions_df.loc[region_index,'chr']\n",
    "start,end = regions_df.loc[region_index,'start'],regions_df.loc[region_index,'end']\n",
    "summit = regions_df.loc[region_index,'summit']\n",
    "\n",
    "start_use = int(start+summit - input_len/2)+1\n",
    "end_use = int(start + summit + input_len/2)\n",
    "\n",
    "middle = int((start+end)/2)\n",
    "nstart = middle-int(input_len/2)\n",
    "nend = nstart + input_len\n",
    "\n",
    "#fasta format\n",
    "seq_man = genome.get_seq(chrom,start_use,end_use)\n",
    "\n",
    "#string\n",
    "seq_man2 = str(genome[chrom][(start_use-1):(end_use)])\n",
    "\n",
    "\n",
    "sequence = seq_man2\n",
    "vals = []\n",
    "if len(sequence) == width:\n",
    "    vals.append(sequence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d27dd57-4dfc-4fda-a123-a18811580325",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_SNCs = pd.read_csv(\"extra_data/hg38_panTro6_IGFBP2i_divergent_site.tsv\",sep=\"\\t\",usecols=[0,1,2,3,4])\n",
    "human_SNCs = human_SNCs.reset_index()\n",
    "human_SNCs['ID'] = 'ID_'+human_SNCs['index'].astype('str')\n",
    "human_SNCs['pos'] = human_SNCs['pos(hg38)'] - 216636250 #subtract int_start and 1\n",
    "human_SNCs['d_start'] = human_SNCs['pos(hg38)']-start_use\n",
    "human_SNCs['d_start_match'] = [sequence[x] for x in human_SNCs['d_start']]\n",
    "human_SNCs = human_SNCs.reset_index()\n",
    "human_SNCs['ID'] = 'ID_'+human_SNCs['index'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dff41e5d-4c61-4efc-944d-db9205d22080",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_SNCs['Hg38'] = human_SNCs['Human']\n",
    "human_SNCs['panTro6'] = human_SNCs['Chimp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "202cdd95-dcd8-4b8b-9760-3a8c8559ff3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_0</th>\n",
       "      <th>index</th>\n",
       "      <th>ID</th>\n",
       "      <th>chr</th>\n",
       "      <th>pos(hg38)</th>\n",
       "      <th>Human</th>\n",
       "      <th>Chimp</th>\n",
       "      <th>pos</th>\n",
       "      <th>d_start</th>\n",
       "      <th>d_start_match</th>\n",
       "      <th>Hg38</th>\n",
       "      <th>panTro6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>ID_0</td>\n",
       "      <td>chr2</td>\n",
       "      <td>216638002</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>1752</td>\n",
       "      <td>1751</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ID_1</td>\n",
       "      <td>chr2</td>\n",
       "      <td>216636815</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>565</td>\n",
       "      <td>564</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>ID_2</td>\n",
       "      <td>chr2</td>\n",
       "      <td>216636845</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "      <td>595</td>\n",
       "      <td>594</td>\n",
       "      <td>T</td>\n",
       "      <td>T</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>ID_3</td>\n",
       "      <td>chr2</td>\n",
       "      <td>216636873</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "      <td>623</td>\n",
       "      <td>622</td>\n",
       "      <td>C</td>\n",
       "      <td>C</td>\n",
       "      <td>T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>ID_4</td>\n",
       "      <td>chr2</td>\n",
       "      <td>216636888</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "      <td>638</td>\n",
       "      <td>637</td>\n",
       "      <td>G</td>\n",
       "      <td>G</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level_0  index    ID   chr  pos(hg38) Human Chimp   pos  d_start  \\\n",
       "0        0      0  ID_0  chr2  216638002     G     A  1752     1751   \n",
       "1        1      1  ID_1  chr2  216636815     G     A   565      564   \n",
       "2        2      2  ID_2  chr2  216636845     T     C   595      594   \n",
       "3        3      3  ID_3  chr2  216636873     C     T   623      622   \n",
       "4        4      4  ID_4  chr2  216636888     G     A   638      637   \n",
       "\n",
       "  d_start_match Hg38 panTro6  \n",
       "0             G    G       A  \n",
       "1             G    G       A  \n",
       "2             T    T       C  \n",
       "3             C    C       T  \n",
       "4             G    G       A  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "human_SNCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd2e208d-15a5-476a-936d-e7dd115821d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evo_seq(sequence,position,ref,alt):\n",
    "    if sequence[position]==ref:\n",
    "        mod_seq = sequence[:position] + alt + sequence[position + 1:]\n",
    "    else:\n",
    "        print(\"reference does not occur at position, double check position\")\n",
    "        mod_seq = None\n",
    "    return(mod_seq)\n",
    "\n",
    "def softmax(x, temp=1):\n",
    "    norm_x = x - np.mean(x,axis=1, keepdims=True)\n",
    "    return np.exp(temp*norm_x)/np.sum(np.exp(temp*norm_x), axis=1, keepdims=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1dafe8ca-dca3-4ad7-9b9f-0723dbecd503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_binary_combinations(num_bits):\n",
    "    num_combinations = 2 ** num_bits\n",
    "    format_string = f'{{:0{num_bits}b}}'\n",
    "    combinations = []\n",
    "    for i in range(num_combinations):\n",
    "        binary_string = format_string.format(i)\n",
    "        combinations.append([int(bit) for bit in binary_string])\n",
    "    return combinations\n",
    "\n",
    "# Example usage for 12 binary variables\n",
    "num_variables = len(human_SNCs.index)\n",
    "combinations = generate_binary_combinations(num_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e430124e-b77b-4bf9-afad-8d9a33a28b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mutated_sequences = []\n",
    "all_mutated_sequences_df = []\n",
    "i = 0\n",
    "ref_sequences = []\n",
    "\n",
    "for comb in combinations:\n",
    "    positions = np.where(np.array(comb) == 1)[0]\n",
    "    human_SNCs_comb = human_SNCs.iloc[positions].copy()\n",
    "\n",
    "#    if len(human_SNCs_comb.index)==0:\n",
    "#        comb_sequence = sequence\n",
    "\n",
    "    comb_sequence = sequence\n",
    "    \n",
    "    for SNC in human_SNCs_comb.index:\n",
    "        position,ref,alt = human_SNCs_comb.loc[SNC,'d_start'],human_SNCs_comb.loc[SNC,'Hg38'],human_SNCs_comb.loc[SNC,'panTro6']\n",
    "\n",
    "        comb_sequence = evo_seq(comb_sequence,position,ref,alt)\n",
    "\n",
    "    \n",
    "    all_mutated_sequences.append(comb_sequence)\n",
    "    ref_sequences.append(sequence)\n",
    "    \n",
    "    concatenated_ids = \"_\".join(human_SNCs_comb['ID'])\n",
    "    total_mutations = np.sum(comb)\n",
    "    \n",
    "    all_mutated_sequences_df.append(dict(sequence_id=i,ntot=total_mutations,SNC=concatenated_ids))\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "05e9d806-b24e-470b-aac3-4b76a08fa3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mutated_sequences_df = pd.DataFrame(all_mutated_sequences_df)\n",
    "all_mutated_sequences_ohe = one_hot.dna_to_one_hot(all_mutated_sequences)\n",
    "ref_sequences_ohe = one_hot.dna_to_one_hot(ref_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ccc12dae-2b44-4908-93ff-53bd684e2f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ref_batch_preds = model.predict(ref_sequences_ohe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e9a4dba4-6a45-45ef-bfb1-f5c1f3e6456d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df65d561-6186-46db-8873-ea1d79f3b58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "43c5aae5-bd40-41de-8e8c-917413a42055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_0\n",
      "got the model\n",
      "predict reference sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/jjanssens/.local/lib/python3.10/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict mutations sequence\n",
      "fold_1\n",
      "got the model\n",
      "predict reference sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/jjanssens/.local/lib/python3.10/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict mutations sequence\n",
      "fold_2\n",
      "got the model\n",
      "predict reference sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/jjanssens/.local/lib/python3.10/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict mutations sequence\n",
      "fold_3\n",
      "got the model\n",
      "predict reference sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/jjanssens/.local/lib/python3.10/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict mutations sequence\n",
      "fold_4\n",
      "got the model\n",
      "predict reference sequence\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cluster/home/jjanssens/.local/lib/python3.10/site-packages/keras/engine/training_v1.py:2079: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predict mutations sequence\n"
     ]
    }
   ],
   "source": [
    "for fold in ['fold_0','fold_1','fold_2','fold_3','fold_4']:\n",
    "    print(fold)\n",
    "    model_path = 'celltype_models_human/modelv1_enterocytes/'+fold+'/output/models/chrombpnet_nobias.h5'\n",
    "    \n",
    "    custom_objects={\"multinomial_nll\": losses.multinomial_nll, \"tf\": tf}    \n",
    "    get_custom_objects().update(custom_objects)    \n",
    "    model=load_model(model_path,compile=False)\n",
    "    print(\"got the model\")\n",
    "\n",
    "    ref_logcount_preds=[]\n",
    "    alt_logcount_preds=[]\n",
    "    ref_prob_preds=[]\n",
    "    alt_prob_preds=[]\n",
    "\n",
    "    print(\"predict reference sequence\")\n",
    "    ref_batch_preds = model.predict(ref_sequences_ohe)\n",
    "    time.sleep(5)\n",
    "\n",
    "    print(\"predict mutations sequence\")\n",
    "    alt_batch_preds = model.predict(all_mutated_sequences_ohe)\n",
    "    time.sleep(5)\n",
    "\n",
    "    ref_logcount_preds.extend(np.squeeze(ref_batch_preds[1]))\n",
    "    alt_logcount_preds.extend(np.squeeze(alt_batch_preds[1]))\n",
    "    \n",
    "    ref_prob_preds.extend(np.squeeze(softmax(ref_batch_preds[0])))\n",
    "    alt_prob_preds.extend(np.squeeze(softmax(alt_batch_preds[0])))\n",
    "\n",
    "    ref_logcount_preds = np.array(ref_logcount_preds)\n",
    "    alt_logcount_preds = np.array(alt_logcount_preds)\n",
    "    ref_prob_preds = np.array(ref_prob_preds)\n",
    "    alt_prob_preds = np.array(alt_prob_preds)\n",
    "\n",
    "    from scipy.spatial.distance import jensenshannon\n",
    "    \n",
    "    log_counts_diff = alt_logcount_preds - ref_logcount_preds\n",
    "    log_probs_diff_abs_sum =  np.sum(np.abs(np.log(alt_prob_preds) -  np.log(ref_prob_preds)),axis=1)*np.sign(log_counts_diff)\n",
    "    probs_jsd_diff = np.array([jensenshannon(x,y) for x,y in zip(alt_prob_preds, ref_prob_preds)])*np.sign(log_counts_diff)\n",
    "\n",
    "    all_mutated_sequences_df[fold+'--logcount_preds'] = alt_logcount_preds\n",
    "    all_mutated_sequences_df[fold+'--log_counts_diff'] = log_counts_diff\n",
    "    all_mutated_sequences_df[fold+'--log_probs_diff_abs_sum'] = log_probs_diff_abs_sum\n",
    "    all_mutated_sequences_df[fold+'--probs_jsd_diff'] = probs_jsd_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "550ffff9-4769-43ea-8c2b-67b6070cb4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_counts_diff_columns = [x for x in all_mutated_sequences_df.columns if 'log_counts_diff' in x]\n",
    "log_probs_diff_abs_sum_columns = [x for x in all_mutated_sequences_df.columns if 'log_probs_diff_abs_sum' in x]\n",
    "probs_jsd_diff_columns = [x for x in all_mutated_sequences_df.columns if 'probs_jsd_diff' in x]\n",
    "logcount_preds_columns = [x for x in all_mutated_sequences_df.columns if 'logcount_preds' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cb8c6410-23be-475d-ba2f-868c5b752ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mutated_sequences_df['log_counts_diff_avg'] = all_mutated_sequences_df[log_counts_diff_columns].T.mean()\n",
    "all_mutated_sequences_df['logcount_preds_avg'] = all_mutated_sequences_df[logcount_preds_columns].T.mean()\n",
    "\n",
    "all_mutated_sequences_df['log_probs_diff_abs_sum_avg'] = all_mutated_sequences_df[log_probs_diff_abs_sum_columns].T.mean()\n",
    "all_mutated_sequences_df['probs_jsd_diff_avg'] = all_mutated_sequences_df[probs_jsd_diff_columns].T.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8d7571d8-c89e-406d-a93d-5ab68088ca42",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mutated_sequences_df.to_csv(\"SNC_IGFBP2_study_effects_wcounts.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bdbee6bc-2ae1-4c4b-a3fc-26dd33030611",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mutated_sequences_df.to_csv(\"SNC_IGFBP2_study_effects.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9b5a7a9-dbb0-4065-8e06-7fd96fd94be3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>ntot</th>\n",
       "      <th>SNC</th>\n",
       "      <th>fold_0--logcount_preds</th>\n",
       "      <th>fold_0--log_counts_diff</th>\n",
       "      <th>fold_0--log_probs_diff_abs_sum</th>\n",
       "      <th>fold_0--probs_jsd_diff</th>\n",
       "      <th>fold_1--logcount_preds</th>\n",
       "      <th>fold_1--log_counts_diff</th>\n",
       "      <th>fold_1--log_probs_diff_abs_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>fold_3--log_probs_diff_abs_sum</th>\n",
       "      <th>fold_3--probs_jsd_diff</th>\n",
       "      <th>fold_4--logcount_preds</th>\n",
       "      <th>fold_4--log_counts_diff</th>\n",
       "      <th>fold_4--log_probs_diff_abs_sum</th>\n",
       "      <th>fold_4--probs_jsd_diff</th>\n",
       "      <th>log_counts_diff_avg</th>\n",
       "      <th>logcount_preds_avg</th>\n",
       "      <th>log_probs_diff_abs_sum_avg</th>\n",
       "      <th>probs_jsd_diff_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>6.833225</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.716840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.598041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.651723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ID_4</td>\n",
       "      <td>6.638362</td>\n",
       "      <td>-0.194863</td>\n",
       "      <td>-84.390945</td>\n",
       "      <td>-0.039753</td>\n",
       "      <td>6.548262</td>\n",
       "      <td>-0.168579</td>\n",
       "      <td>-68.829819</td>\n",
       "      <td>...</td>\n",
       "      <td>-229.828857</td>\n",
       "      <td>-0.092687</td>\n",
       "      <td>6.351476</td>\n",
       "      <td>-0.246565</td>\n",
       "      <td>-140.442535</td>\n",
       "      <td>-0.059369</td>\n",
       "      <td>-0.266680</td>\n",
       "      <td>6.385043</td>\n",
       "      <td>-141.136429</td>\n",
       "      <td>-0.059589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>ID_3</td>\n",
       "      <td>6.908408</td>\n",
       "      <td>0.075182</td>\n",
       "      <td>33.376160</td>\n",
       "      <td>0.017666</td>\n",
       "      <td>6.784744</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>42.209888</td>\n",
       "      <td>...</td>\n",
       "      <td>28.959709</td>\n",
       "      <td>0.014956</td>\n",
       "      <td>6.710413</td>\n",
       "      <td>0.112372</td>\n",
       "      <td>59.539883</td>\n",
       "      <td>0.026189</td>\n",
       "      <td>0.090242</td>\n",
       "      <td>6.741964</td>\n",
       "      <td>52.933197</td>\n",
       "      <td>0.023889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>ID_3_ID_4</td>\n",
       "      <td>6.714245</td>\n",
       "      <td>-0.118980</td>\n",
       "      <td>-43.872704</td>\n",
       "      <td>-0.024578</td>\n",
       "      <td>6.600187</td>\n",
       "      <td>-0.116653</td>\n",
       "      <td>-46.258316</td>\n",
       "      <td>...</td>\n",
       "      <td>-198.313690</td>\n",
       "      <td>-0.080159</td>\n",
       "      <td>6.474278</td>\n",
       "      <td>-0.123763</td>\n",
       "      <td>-57.537403</td>\n",
       "      <td>-0.026591</td>\n",
       "      <td>-0.188454</td>\n",
       "      <td>6.463269</td>\n",
       "      <td>-88.342102</td>\n",
       "      <td>-0.039497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>ID_2</td>\n",
       "      <td>6.869263</td>\n",
       "      <td>0.036038</td>\n",
       "      <td>19.356945</td>\n",
       "      <td>0.013294</td>\n",
       "      <td>6.733350</td>\n",
       "      <td>0.016510</td>\n",
       "      <td>22.509020</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.728277</td>\n",
       "      <td>-0.009528</td>\n",
       "      <td>6.600073</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>17.331200</td>\n",
       "      <td>0.014218</td>\n",
       "      <td>0.007536</td>\n",
       "      <td>6.659259</td>\n",
       "      <td>7.298970</td>\n",
       "      <td>0.004223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>ID_2_ID_4</td>\n",
       "      <td>6.676192</td>\n",
       "      <td>-0.157033</td>\n",
       "      <td>-66.029663</td>\n",
       "      <td>-0.031988</td>\n",
       "      <td>6.556505</td>\n",
       "      <td>-0.160335</td>\n",
       "      <td>-60.463684</td>\n",
       "      <td>...</td>\n",
       "      <td>-244.163391</td>\n",
       "      <td>-0.098747</td>\n",
       "      <td>6.354335</td>\n",
       "      <td>-0.243705</td>\n",
       "      <td>-134.351837</td>\n",
       "      <td>-0.057335</td>\n",
       "      <td>-0.261388</td>\n",
       "      <td>6.390335</td>\n",
       "      <td>-137.238159</td>\n",
       "      <td>-0.058376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>ID_2_ID_3</td>\n",
       "      <td>6.947199</td>\n",
       "      <td>0.113974</td>\n",
       "      <td>49.575054</td>\n",
       "      <td>0.027575</td>\n",
       "      <td>6.799324</td>\n",
       "      <td>0.082483</td>\n",
       "      <td>64.620972</td>\n",
       "      <td>...</td>\n",
       "      <td>28.025793</td>\n",
       "      <td>0.016663</td>\n",
       "      <td>6.709045</td>\n",
       "      <td>0.111004</td>\n",
       "      <td>67.227264</td>\n",
       "      <td>0.032270</td>\n",
       "      <td>0.096637</td>\n",
       "      <td>6.748360</td>\n",
       "      <td>62.098396</td>\n",
       "      <td>0.030563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>ID_2_ID_3_ID_4</td>\n",
       "      <td>6.757178</td>\n",
       "      <td>-0.076047</td>\n",
       "      <td>-33.062180</td>\n",
       "      <td>-0.023444</td>\n",
       "      <td>6.607722</td>\n",
       "      <td>-0.109118</td>\n",
       "      <td>-38.506508</td>\n",
       "      <td>...</td>\n",
       "      <td>-211.703812</td>\n",
       "      <td>-0.085951</td>\n",
       "      <td>6.471277</td>\n",
       "      <td>-0.126764</td>\n",
       "      <td>-59.454163</td>\n",
       "      <td>-0.029807</td>\n",
       "      <td>-0.183848</td>\n",
       "      <td>6.467874</td>\n",
       "      <td>-86.749290</td>\n",
       "      <td>-0.041034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>ID_1</td>\n",
       "      <td>6.839322</td>\n",
       "      <td>0.006096</td>\n",
       "      <td>9.928485</td>\n",
       "      <td>0.012224</td>\n",
       "      <td>6.747108</td>\n",
       "      <td>0.030267</td>\n",
       "      <td>14.280170</td>\n",
       "      <td>...</td>\n",
       "      <td>8.058056</td>\n",
       "      <td>0.010833</td>\n",
       "      <td>6.603245</td>\n",
       "      <td>0.005204</td>\n",
       "      <td>11.884699</td>\n",
       "      <td>0.011219</td>\n",
       "      <td>0.013365</td>\n",
       "      <td>6.665088</td>\n",
       "      <td>11.224241</td>\n",
       "      <td>0.011421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>ID_1_ID_4</td>\n",
       "      <td>6.647251</td>\n",
       "      <td>-0.185974</td>\n",
       "      <td>-88.991043</td>\n",
       "      <td>-0.043357</td>\n",
       "      <td>6.573060</td>\n",
       "      <td>-0.143780</td>\n",
       "      <td>-59.301155</td>\n",
       "      <td>...</td>\n",
       "      <td>-221.167084</td>\n",
       "      <td>-0.089891</td>\n",
       "      <td>6.360095</td>\n",
       "      <td>-0.237946</td>\n",
       "      <td>-138.040649</td>\n",
       "      <td>-0.059129</td>\n",
       "      <td>-0.249972</td>\n",
       "      <td>6.401752</td>\n",
       "      <td>-137.320145</td>\n",
       "      <td>-0.059308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>ID_1_ID_3</td>\n",
       "      <td>6.913565</td>\n",
       "      <td>0.080340</td>\n",
       "      <td>32.909702</td>\n",
       "      <td>0.020434</td>\n",
       "      <td>6.811252</td>\n",
       "      <td>0.094412</td>\n",
       "      <td>53.104004</td>\n",
       "      <td>...</td>\n",
       "      <td>30.175224</td>\n",
       "      <td>0.017800</td>\n",
       "      <td>6.714089</td>\n",
       "      <td>0.116049</td>\n",
       "      <td>65.352859</td>\n",
       "      <td>0.030921</td>\n",
       "      <td>0.101650</td>\n",
       "      <td>6.753373</td>\n",
       "      <td>57.249096</td>\n",
       "      <td>0.027807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>ID_1_ID_3_ID_4</td>\n",
       "      <td>6.723635</td>\n",
       "      <td>-0.109591</td>\n",
       "      <td>-49.942459</td>\n",
       "      <td>-0.029306</td>\n",
       "      <td>6.619830</td>\n",
       "      <td>-0.097010</td>\n",
       "      <td>-37.600601</td>\n",
       "      <td>...</td>\n",
       "      <td>-190.842377</td>\n",
       "      <td>-0.077955</td>\n",
       "      <td>6.477899</td>\n",
       "      <td>-0.120142</td>\n",
       "      <td>-54.725834</td>\n",
       "      <td>-0.027859</td>\n",
       "      <td>-0.175514</td>\n",
       "      <td>6.476209</td>\n",
       "      <td>-86.058167</td>\n",
       "      <td>-0.040587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>ID_1_ID_2</td>\n",
       "      <td>6.871982</td>\n",
       "      <td>0.038756</td>\n",
       "      <td>18.814302</td>\n",
       "      <td>0.015273</td>\n",
       "      <td>6.774115</td>\n",
       "      <td>0.057275</td>\n",
       "      <td>37.457645</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.258073</td>\n",
       "      <td>-0.014075</td>\n",
       "      <td>6.613113</td>\n",
       "      <td>0.015073</td>\n",
       "      <td>26.764166</td>\n",
       "      <td>0.019324</td>\n",
       "      <td>0.023200</td>\n",
       "      <td>6.674923</td>\n",
       "      <td>16.650949</td>\n",
       "      <td>0.011717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>ID_1_ID_2_ID_4</td>\n",
       "      <td>6.681010</td>\n",
       "      <td>-0.152215</td>\n",
       "      <td>-72.761658</td>\n",
       "      <td>-0.036208</td>\n",
       "      <td>6.597332</td>\n",
       "      <td>-0.119508</td>\n",
       "      <td>-48.075249</td>\n",
       "      <td>...</td>\n",
       "      <td>-235.511200</td>\n",
       "      <td>-0.095748</td>\n",
       "      <td>6.374428</td>\n",
       "      <td>-0.223612</td>\n",
       "      <td>-124.062660</td>\n",
       "      <td>-0.053847</td>\n",
       "      <td>-0.240836</td>\n",
       "      <td>6.410886</td>\n",
       "      <td>-131.886490</td>\n",
       "      <td>-0.057599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>ID_1_ID_2_ID_3</td>\n",
       "      <td>6.948600</td>\n",
       "      <td>0.115375</td>\n",
       "      <td>46.283890</td>\n",
       "      <td>0.027322</td>\n",
       "      <td>6.844509</td>\n",
       "      <td>0.127669</td>\n",
       "      <td>83.030151</td>\n",
       "      <td>...</td>\n",
       "      <td>28.921104</td>\n",
       "      <td>0.019142</td>\n",
       "      <td>6.721888</td>\n",
       "      <td>0.123847</td>\n",
       "      <td>75.414810</td>\n",
       "      <td>0.037028</td>\n",
       "      <td>0.113344</td>\n",
       "      <td>6.765067</td>\n",
       "      <td>68.316727</td>\n",
       "      <td>0.034294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>ID_1_ID_2_ID_3_ID_4</td>\n",
       "      <td>6.762633</td>\n",
       "      <td>-0.070592</td>\n",
       "      <td>-40.603874</td>\n",
       "      <td>-0.027099</td>\n",
       "      <td>6.650369</td>\n",
       "      <td>-0.066472</td>\n",
       "      <td>-28.715450</td>\n",
       "      <td>...</td>\n",
       "      <td>-203.784164</td>\n",
       "      <td>-0.083311</td>\n",
       "      <td>6.488821</td>\n",
       "      <td>-0.109220</td>\n",
       "      <td>-51.964218</td>\n",
       "      <td>-0.030058</td>\n",
       "      <td>-0.164897</td>\n",
       "      <td>6.486825</td>\n",
       "      <td>-83.659096</td>\n",
       "      <td>-0.042125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>ID_0</td>\n",
       "      <td>6.834239</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>1.461514</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>6.719839</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>2.456373</td>\n",
       "      <td>...</td>\n",
       "      <td>1.736870</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>6.592869</td>\n",
       "      <td>-0.005172</td>\n",
       "      <td>-1.718345</td>\n",
       "      <td>-0.000708</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>6.651865</td>\n",
       "      <td>1.305019</td>\n",
       "      <td>0.000584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>ID_0_ID_4</td>\n",
       "      <td>6.639375</td>\n",
       "      <td>-0.193850</td>\n",
       "      <td>-84.639687</td>\n",
       "      <td>-0.039778</td>\n",
       "      <td>6.551261</td>\n",
       "      <td>-0.165579</td>\n",
       "      <td>-69.920303</td>\n",
       "      <td>...</td>\n",
       "      <td>-229.592926</td>\n",
       "      <td>-0.092665</td>\n",
       "      <td>6.346303</td>\n",
       "      <td>-0.251737</td>\n",
       "      <td>-141.014267</td>\n",
       "      <td>-0.059406</td>\n",
       "      <td>-0.266538</td>\n",
       "      <td>6.385185</td>\n",
       "      <td>-141.731201</td>\n",
       "      <td>-0.059646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>ID_0_ID_3</td>\n",
       "      <td>6.909420</td>\n",
       "      <td>0.076195</td>\n",
       "      <td>33.127365</td>\n",
       "      <td>0.017661</td>\n",
       "      <td>6.787742</td>\n",
       "      <td>0.070902</td>\n",
       "      <td>41.211578</td>\n",
       "      <td>...</td>\n",
       "      <td>29.202429</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>6.705241</td>\n",
       "      <td>0.107200</td>\n",
       "      <td>58.959827</td>\n",
       "      <td>0.026169</td>\n",
       "      <td>0.090384</td>\n",
       "      <td>6.742107</td>\n",
       "      <td>52.346771</td>\n",
       "      <td>0.023862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>ID_0_ID_3_ID_4</td>\n",
       "      <td>6.715258</td>\n",
       "      <td>-0.117968</td>\n",
       "      <td>-44.125122</td>\n",
       "      <td>-0.024601</td>\n",
       "      <td>6.603186</td>\n",
       "      <td>-0.113654</td>\n",
       "      <td>-47.346748</td>\n",
       "      <td>...</td>\n",
       "      <td>-198.076263</td>\n",
       "      <td>-0.080137</td>\n",
       "      <td>6.469105</td>\n",
       "      <td>-0.128935</td>\n",
       "      <td>-58.117027</td>\n",
       "      <td>-0.026630</td>\n",
       "      <td>-0.188311</td>\n",
       "      <td>6.463412</td>\n",
       "      <td>-88.940872</td>\n",
       "      <td>-0.039549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "      <td>ID_0_ID_2</td>\n",
       "      <td>6.870276</td>\n",
       "      <td>0.037051</td>\n",
       "      <td>19.129436</td>\n",
       "      <td>0.013297</td>\n",
       "      <td>6.736350</td>\n",
       "      <td>0.019510</td>\n",
       "      <td>22.308903</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.447861</td>\n",
       "      <td>-0.009562</td>\n",
       "      <td>6.594903</td>\n",
       "      <td>-0.003138</td>\n",
       "      <td>-17.243809</td>\n",
       "      <td>-0.014226</td>\n",
       "      <td>0.007679</td>\n",
       "      <td>6.659402</td>\n",
       "      <td>-0.222828</td>\n",
       "      <td>-0.001483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>ID_0_ID_2_ID_4</td>\n",
       "      <td>6.677205</td>\n",
       "      <td>-0.156021</td>\n",
       "      <td>-66.282684</td>\n",
       "      <td>-0.032013</td>\n",
       "      <td>6.559504</td>\n",
       "      <td>-0.157336</td>\n",
       "      <td>-61.549873</td>\n",
       "      <td>...</td>\n",
       "      <td>-243.928391</td>\n",
       "      <td>-0.098725</td>\n",
       "      <td>6.349163</td>\n",
       "      <td>-0.248878</td>\n",
       "      <td>-134.924011</td>\n",
       "      <td>-0.057372</td>\n",
       "      <td>-0.261245</td>\n",
       "      <td>6.390478</td>\n",
       "      <td>-137.833176</td>\n",
       "      <td>-0.058431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>ID_0_ID_2_ID_3</td>\n",
       "      <td>6.948213</td>\n",
       "      <td>0.114987</td>\n",
       "      <td>49.326744</td>\n",
       "      <td>0.027566</td>\n",
       "      <td>6.802323</td>\n",
       "      <td>0.085483</td>\n",
       "      <td>63.555706</td>\n",
       "      <td>...</td>\n",
       "      <td>28.268440</td>\n",
       "      <td>0.016699</td>\n",
       "      <td>6.703873</td>\n",
       "      <td>0.105833</td>\n",
       "      <td>66.648697</td>\n",
       "      <td>0.032250</td>\n",
       "      <td>0.096780</td>\n",
       "      <td>6.748503</td>\n",
       "      <td>61.501709</td>\n",
       "      <td>0.030533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>ID_0_ID_2_ID_3_ID_4</td>\n",
       "      <td>6.758191</td>\n",
       "      <td>-0.075035</td>\n",
       "      <td>-33.364197</td>\n",
       "      <td>-0.023460</td>\n",
       "      <td>6.610721</td>\n",
       "      <td>-0.106120</td>\n",
       "      <td>-39.595005</td>\n",
       "      <td>...</td>\n",
       "      <td>-211.466858</td>\n",
       "      <td>-0.085929</td>\n",
       "      <td>6.466105</td>\n",
       "      <td>-0.131936</td>\n",
       "      <td>-60.034431</td>\n",
       "      <td>-0.029840</td>\n",
       "      <td>-0.183706</td>\n",
       "      <td>6.468018</td>\n",
       "      <td>-87.357292</td>\n",
       "      <td>-0.041076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>ID_0_ID_1</td>\n",
       "      <td>6.840333</td>\n",
       "      <td>0.007108</td>\n",
       "      <td>10.734421</td>\n",
       "      <td>0.012244</td>\n",
       "      <td>6.750106</td>\n",
       "      <td>0.033266</td>\n",
       "      <td>14.645039</td>\n",
       "      <td>...</td>\n",
       "      <td>9.478691</td>\n",
       "      <td>0.010867</td>\n",
       "      <td>6.598074</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>12.253799</td>\n",
       "      <td>0.011234</td>\n",
       "      <td>0.013508</td>\n",
       "      <td>6.665231</td>\n",
       "      <td>11.724020</td>\n",
       "      <td>0.011439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>3</td>\n",
       "      <td>ID_0_ID_1_ID_4</td>\n",
       "      <td>6.648264</td>\n",
       "      <td>-0.184961</td>\n",
       "      <td>-89.239075</td>\n",
       "      <td>-0.043380</td>\n",
       "      <td>6.576059</td>\n",
       "      <td>-0.140781</td>\n",
       "      <td>-60.378574</td>\n",
       "      <td>...</td>\n",
       "      <td>-220.930801</td>\n",
       "      <td>-0.089869</td>\n",
       "      <td>6.354923</td>\n",
       "      <td>-0.243117</td>\n",
       "      <td>-138.612808</td>\n",
       "      <td>-0.059165</td>\n",
       "      <td>-0.249829</td>\n",
       "      <td>6.401894</td>\n",
       "      <td>-137.910843</td>\n",
       "      <td>-0.059361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>ID_0_ID_1_ID_3</td>\n",
       "      <td>6.914577</td>\n",
       "      <td>0.081351</td>\n",
       "      <td>32.663322</td>\n",
       "      <td>0.020431</td>\n",
       "      <td>6.814252</td>\n",
       "      <td>0.097412</td>\n",
       "      <td>52.028835</td>\n",
       "      <td>...</td>\n",
       "      <td>30.418447</td>\n",
       "      <td>0.017837</td>\n",
       "      <td>6.708918</td>\n",
       "      <td>0.110877</td>\n",
       "      <td>64.773895</td>\n",
       "      <td>0.030901</td>\n",
       "      <td>0.101793</td>\n",
       "      <td>6.753516</td>\n",
       "      <td>56.647011</td>\n",
       "      <td>0.027776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>ID_0_ID_1_ID_3_ID_4</td>\n",
       "      <td>6.724648</td>\n",
       "      <td>-0.108578</td>\n",
       "      <td>-50.194733</td>\n",
       "      <td>-0.029326</td>\n",
       "      <td>6.622829</td>\n",
       "      <td>-0.094011</td>\n",
       "      <td>-38.664196</td>\n",
       "      <td>...</td>\n",
       "      <td>-190.603821</td>\n",
       "      <td>-0.077933</td>\n",
       "      <td>6.472729</td>\n",
       "      <td>-0.125312</td>\n",
       "      <td>-55.303555</td>\n",
       "      <td>-0.027893</td>\n",
       "      <td>-0.175371</td>\n",
       "      <td>6.476352</td>\n",
       "      <td>-86.649765</td>\n",
       "      <td>-0.040631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>ID_0_ID_1_ID_2</td>\n",
       "      <td>6.872993</td>\n",
       "      <td>0.039768</td>\n",
       "      <td>18.660263</td>\n",
       "      <td>0.015279</td>\n",
       "      <td>6.777113</td>\n",
       "      <td>0.060273</td>\n",
       "      <td>36.470142</td>\n",
       "      <td>...</td>\n",
       "      <td>-13.938702</td>\n",
       "      <td>-0.014098</td>\n",
       "      <td>6.607942</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>26.275761</td>\n",
       "      <td>0.019323</td>\n",
       "      <td>0.023343</td>\n",
       "      <td>6.675065</td>\n",
       "      <td>16.539925</td>\n",
       "      <td>0.011711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>4</td>\n",
       "      <td>ID_0_ID_1_ID_2_ID_4</td>\n",
       "      <td>6.682023</td>\n",
       "      <td>-0.151202</td>\n",
       "      <td>-73.013107</td>\n",
       "      <td>-0.036231</td>\n",
       "      <td>6.600331</td>\n",
       "      <td>-0.116509</td>\n",
       "      <td>-49.153477</td>\n",
       "      <td>...</td>\n",
       "      <td>-235.275192</td>\n",
       "      <td>-0.095726</td>\n",
       "      <td>6.369256</td>\n",
       "      <td>-0.228784</td>\n",
       "      <td>-124.634659</td>\n",
       "      <td>-0.053883</td>\n",
       "      <td>-0.240694</td>\n",
       "      <td>6.411029</td>\n",
       "      <td>-132.478821</td>\n",
       "      <td>-0.057647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>4</td>\n",
       "      <td>ID_0_ID_1_ID_2_ID_3</td>\n",
       "      <td>6.949613</td>\n",
       "      <td>0.116388</td>\n",
       "      <td>46.036201</td>\n",
       "      <td>0.027314</td>\n",
       "      <td>6.847509</td>\n",
       "      <td>0.130669</td>\n",
       "      <td>81.949036</td>\n",
       "      <td>...</td>\n",
       "      <td>29.163673</td>\n",
       "      <td>0.019173</td>\n",
       "      <td>6.716715</td>\n",
       "      <td>0.118674</td>\n",
       "      <td>74.836494</td>\n",
       "      <td>0.037007</td>\n",
       "      <td>0.113487</td>\n",
       "      <td>6.765210</td>\n",
       "      <td>67.715622</td>\n",
       "      <td>0.034261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>ID_0_ID_1_ID_2_ID_3_ID_4</td>\n",
       "      <td>6.763645</td>\n",
       "      <td>-0.069580</td>\n",
       "      <td>-40.867828</td>\n",
       "      <td>-0.027115</td>\n",
       "      <td>6.653368</td>\n",
       "      <td>-0.063472</td>\n",
       "      <td>-30.300707</td>\n",
       "      <td>...</td>\n",
       "      <td>-203.545898</td>\n",
       "      <td>-0.083289</td>\n",
       "      <td>6.483650</td>\n",
       "      <td>-0.114391</td>\n",
       "      <td>-52.546257</td>\n",
       "      <td>-0.030085</td>\n",
       "      <td>-0.164755</td>\n",
       "      <td>6.486968</td>\n",
       "      <td>-84.358963</td>\n",
       "      <td>-0.042155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>32 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sequence_id  ntot                       SNC  fold_0--logcount_preds  \\\n",
       "0             0     0                                          6.833225   \n",
       "1             1     1                      ID_4                6.638362   \n",
       "2             2     1                      ID_3                6.908408   \n",
       "3             3     2                 ID_3_ID_4                6.714245   \n",
       "4             4     1                      ID_2                6.869263   \n",
       "5             5     2                 ID_2_ID_4                6.676192   \n",
       "6             6     2                 ID_2_ID_3                6.947199   \n",
       "7             7     3            ID_2_ID_3_ID_4                6.757178   \n",
       "8             8     1                      ID_1                6.839322   \n",
       "9             9     2                 ID_1_ID_4                6.647251   \n",
       "10           10     2                 ID_1_ID_3                6.913565   \n",
       "11           11     3            ID_1_ID_3_ID_4                6.723635   \n",
       "12           12     2                 ID_1_ID_2                6.871982   \n",
       "13           13     3            ID_1_ID_2_ID_4                6.681010   \n",
       "14           14     3            ID_1_ID_2_ID_3                6.948600   \n",
       "15           15     4       ID_1_ID_2_ID_3_ID_4                6.762633   \n",
       "16           16     1                      ID_0                6.834239   \n",
       "17           17     2                 ID_0_ID_4                6.639375   \n",
       "18           18     2                 ID_0_ID_3                6.909420   \n",
       "19           19     3            ID_0_ID_3_ID_4                6.715258   \n",
       "20           20     2                 ID_0_ID_2                6.870276   \n",
       "21           21     3            ID_0_ID_2_ID_4                6.677205   \n",
       "22           22     3            ID_0_ID_2_ID_3                6.948213   \n",
       "23           23     4       ID_0_ID_2_ID_3_ID_4                6.758191   \n",
       "24           24     2                 ID_0_ID_1                6.840333   \n",
       "25           25     3            ID_0_ID_1_ID_4                6.648264   \n",
       "26           26     3            ID_0_ID_1_ID_3                6.914577   \n",
       "27           27     4       ID_0_ID_1_ID_3_ID_4                6.724648   \n",
       "28           28     3            ID_0_ID_1_ID_2                6.872993   \n",
       "29           29     4       ID_0_ID_1_ID_2_ID_4                6.682023   \n",
       "30           30     4       ID_0_ID_1_ID_2_ID_3                6.949613   \n",
       "31           31     5  ID_0_ID_1_ID_2_ID_3_ID_4                6.763645   \n",
       "\n",
       "    fold_0--log_counts_diff  fold_0--log_probs_diff_abs_sum  \\\n",
       "0                  0.000000                        0.000000   \n",
       "1                 -0.194863                      -84.390945   \n",
       "2                  0.075182                       33.376160   \n",
       "3                 -0.118980                      -43.872704   \n",
       "4                  0.036038                       19.356945   \n",
       "5                 -0.157033                      -66.029663   \n",
       "6                  0.113974                       49.575054   \n",
       "7                 -0.076047                      -33.062180   \n",
       "8                  0.006096                        9.928485   \n",
       "9                 -0.185974                      -88.991043   \n",
       "10                 0.080340                       32.909702   \n",
       "11                -0.109591                      -49.942459   \n",
       "12                 0.038756                       18.814302   \n",
       "13                -0.152215                      -72.761658   \n",
       "14                 0.115375                       46.283890   \n",
       "15                -0.070592                      -40.603874   \n",
       "16                 0.001013                        1.461514   \n",
       "17                -0.193850                      -84.639687   \n",
       "18                 0.076195                       33.127365   \n",
       "19                -0.117968                      -44.125122   \n",
       "20                 0.037051                       19.129436   \n",
       "21                -0.156021                      -66.282684   \n",
       "22                 0.114987                       49.326744   \n",
       "23                -0.075035                      -33.364197   \n",
       "24                 0.007108                       10.734421   \n",
       "25                -0.184961                      -89.239075   \n",
       "26                 0.081351                       32.663322   \n",
       "27                -0.108578                      -50.194733   \n",
       "28                 0.039768                       18.660263   \n",
       "29                -0.151202                      -73.013107   \n",
       "30                 0.116388                       46.036201   \n",
       "31                -0.069580                      -40.867828   \n",
       "\n",
       "    fold_0--probs_jsd_diff  fold_1--logcount_preds  fold_1--log_counts_diff  \\\n",
       "0                 0.000000                6.716840                 0.000000   \n",
       "1                -0.039753                6.548262                -0.168579   \n",
       "2                 0.017666                6.784744                 0.067904   \n",
       "3                -0.024578                6.600187                -0.116653   \n",
       "4                 0.013294                6.733350                 0.016510   \n",
       "5                -0.031988                6.556505                -0.160335   \n",
       "6                 0.027575                6.799324                 0.082483   \n",
       "7                -0.023444                6.607722                -0.109118   \n",
       "8                 0.012224                6.747108                 0.030267   \n",
       "9                -0.043357                6.573060                -0.143780   \n",
       "10                0.020434                6.811252                 0.094412   \n",
       "11               -0.029306                6.619830                -0.097010   \n",
       "12                0.015273                6.774115                 0.057275   \n",
       "13               -0.036208                6.597332                -0.119508   \n",
       "14                0.027322                6.844509                 0.127669   \n",
       "15               -0.027099                6.650369                -0.066472   \n",
       "16                0.000649                6.719839                 0.002998   \n",
       "17               -0.039778                6.551261                -0.165579   \n",
       "18                0.017661                6.787742                 0.070902   \n",
       "19               -0.024601                6.603186                -0.113654   \n",
       "20                0.013297                6.736350                 0.019510   \n",
       "21               -0.032013                6.559504                -0.157336   \n",
       "22                0.027566                6.802323                 0.085483   \n",
       "23               -0.023460                6.610721                -0.106120   \n",
       "24                0.012244                6.750106                 0.033266   \n",
       "25               -0.043380                6.576059                -0.140781   \n",
       "26                0.020431                6.814252                 0.097412   \n",
       "27               -0.029326                6.622829                -0.094011   \n",
       "28                0.015279                6.777113                 0.060273   \n",
       "29               -0.036231                6.600331                -0.116509   \n",
       "30                0.027314                6.847509                 0.130669   \n",
       "31               -0.027115                6.653368                -0.063472   \n",
       "\n",
       "    fold_1--log_probs_diff_abs_sum  ...  fold_3--log_probs_diff_abs_sum  \\\n",
       "0                         0.000000  ...                        0.000000   \n",
       "1                       -68.829819  ...                     -229.828857   \n",
       "2                        42.209888  ...                       28.959709   \n",
       "3                       -46.258316  ...                     -198.313690   \n",
       "4                        22.509020  ...                      -10.728277   \n",
       "5                       -60.463684  ...                     -244.163391   \n",
       "6                        64.620972  ...                       28.025793   \n",
       "7                       -38.506508  ...                     -211.703812   \n",
       "8                        14.280170  ...                        8.058056   \n",
       "9                       -59.301155  ...                     -221.167084   \n",
       "10                       53.104004  ...                       30.175224   \n",
       "11                      -37.600601  ...                     -190.842377   \n",
       "12                       37.457645  ...                      -13.258073   \n",
       "13                      -48.075249  ...                     -235.511200   \n",
       "14                       83.030151  ...                       28.921104   \n",
       "15                      -28.715450  ...                     -203.784164   \n",
       "16                        2.456373  ...                        1.736870   \n",
       "17                      -69.920303  ...                     -229.592926   \n",
       "18                       41.211578  ...                       29.202429   \n",
       "19                      -47.346748  ...                     -198.076263   \n",
       "20                       22.308903  ...                      -11.447861   \n",
       "21                      -61.549873  ...                     -243.928391   \n",
       "22                       63.555706  ...                       28.268440   \n",
       "23                      -39.595005  ...                     -211.466858   \n",
       "24                       14.645039  ...                        9.478691   \n",
       "25                      -60.378574  ...                     -220.930801   \n",
       "26                       52.028835  ...                       30.418447   \n",
       "27                      -38.664196  ...                     -190.603821   \n",
       "28                       36.470142  ...                      -13.938702   \n",
       "29                      -49.153477  ...                     -235.275192   \n",
       "30                       81.949036  ...                       29.163673   \n",
       "31                      -30.300707  ...                     -203.545898   \n",
       "\n",
       "    fold_3--probs_jsd_diff  fold_4--logcount_preds  fold_4--log_counts_diff  \\\n",
       "0                 0.000000                6.598041                 0.000000   \n",
       "1                -0.092687                6.351476                -0.246565   \n",
       "2                 0.014956                6.710413                 0.112372   \n",
       "3                -0.080159                6.474278                -0.123763   \n",
       "4                -0.009528                6.600073                 0.002033   \n",
       "5                -0.098747                6.354335                -0.243705   \n",
       "6                 0.016663                6.709045                 0.111004   \n",
       "7                -0.085951                6.471277                -0.126764   \n",
       "8                 0.010833                6.603245                 0.005204   \n",
       "9                -0.089891                6.360095                -0.237946   \n",
       "10                0.017800                6.714089                 0.116049   \n",
       "11               -0.077955                6.477899                -0.120142   \n",
       "12               -0.014075                6.613113                 0.015073   \n",
       "13               -0.095748                6.374428                -0.223612   \n",
       "14                0.019142                6.721888                 0.123847   \n",
       "15               -0.083311                6.488821                -0.109220   \n",
       "16                0.000867                6.592869                -0.005172   \n",
       "17               -0.092665                6.346303                -0.251737   \n",
       "18                0.015000                6.705241                 0.107200   \n",
       "19               -0.080137                6.469105                -0.128935   \n",
       "20               -0.009562                6.594903                -0.003138   \n",
       "21               -0.098725                6.349163                -0.248878   \n",
       "22                0.016699                6.703873                 0.105833   \n",
       "23               -0.085929                6.466105                -0.131936   \n",
       "24                0.010867                6.598074                 0.000034   \n",
       "25               -0.089869                6.354923                -0.243117   \n",
       "26                0.017837                6.708918                 0.110877   \n",
       "27               -0.077933                6.472729                -0.125312   \n",
       "28               -0.014098                6.607942                 0.009901   \n",
       "29               -0.095726                6.369256                -0.228784   \n",
       "30                0.019173                6.716715                 0.118674   \n",
       "31               -0.083289                6.483650                -0.114391   \n",
       "\n",
       "    fold_4--log_probs_diff_abs_sum  fold_4--probs_jsd_diff  \\\n",
       "0                         0.000000                0.000000   \n",
       "1                      -140.442535               -0.059369   \n",
       "2                        59.539883                0.026189   \n",
       "3                       -57.537403               -0.026591   \n",
       "4                        17.331200                0.014218   \n",
       "5                      -134.351837               -0.057335   \n",
       "6                        67.227264                0.032270   \n",
       "7                       -59.454163               -0.029807   \n",
       "8                        11.884699                0.011219   \n",
       "9                      -138.040649               -0.059129   \n",
       "10                       65.352859                0.030921   \n",
       "11                      -54.725834               -0.027859   \n",
       "12                       26.764166                0.019324   \n",
       "13                     -124.062660               -0.053847   \n",
       "14                       75.414810                0.037028   \n",
       "15                      -51.964218               -0.030058   \n",
       "16                       -1.718345               -0.000708   \n",
       "17                     -141.014267               -0.059406   \n",
       "18                       58.959827                0.026169   \n",
       "19                      -58.117027               -0.026630   \n",
       "20                      -17.243809               -0.014226   \n",
       "21                     -134.924011               -0.057372   \n",
       "22                       66.648697                0.032250   \n",
       "23                      -60.034431               -0.029840   \n",
       "24                       12.253799                0.011234   \n",
       "25                     -138.612808               -0.059165   \n",
       "26                       64.773895                0.030901   \n",
       "27                      -55.303555               -0.027893   \n",
       "28                       26.275761                0.019323   \n",
       "29                     -124.634659               -0.053883   \n",
       "30                       74.836494                0.037007   \n",
       "31                      -52.546257               -0.030085   \n",
       "\n",
       "    log_counts_diff_avg  logcount_preds_avg  log_probs_diff_abs_sum_avg  \\\n",
       "0              0.000000            6.651723                    0.000000   \n",
       "1             -0.266680            6.385043                 -141.136429   \n",
       "2              0.090242            6.741964                   52.933197   \n",
       "3             -0.188454            6.463269                  -88.342102   \n",
       "4              0.007536            6.659259                    7.298970   \n",
       "5             -0.261388            6.390335                 -137.238159   \n",
       "6              0.096637            6.748360                   62.098396   \n",
       "7             -0.183848            6.467874                  -86.749290   \n",
       "8              0.013365            6.665088                   11.224241   \n",
       "9             -0.249972            6.401752                 -137.320145   \n",
       "10             0.101650            6.753373                   57.249096   \n",
       "11            -0.175514            6.476209                  -86.058167   \n",
       "12             0.023200            6.674923                   16.650949   \n",
       "13            -0.240836            6.410886                 -131.886490   \n",
       "14             0.113344            6.765067                   68.316727   \n",
       "15            -0.164897            6.486825                  -83.659096   \n",
       "16             0.000143            6.651865                    1.305019   \n",
       "17            -0.266538            6.385185                 -141.731201   \n",
       "18             0.090384            6.742107                   52.346771   \n",
       "19            -0.188311            6.463412                  -88.940872   \n",
       "20             0.007679            6.659402                   -0.222828   \n",
       "21            -0.261245            6.390478                 -137.833176   \n",
       "22             0.096780            6.748503                   61.501709   \n",
       "23            -0.183706            6.468018                  -87.357292   \n",
       "24             0.013508            6.665231                   11.724020   \n",
       "25            -0.249829            6.401894                 -137.910843   \n",
       "26             0.101793            6.753516                   56.647011   \n",
       "27            -0.175371            6.476352                  -86.649765   \n",
       "28             0.023343            6.675065                   16.539925   \n",
       "29            -0.240694            6.411029                 -132.478821   \n",
       "30             0.113487            6.765210                   67.715622   \n",
       "31            -0.164755            6.486968                  -84.358963   \n",
       "\n",
       "    probs_jsd_diff_avg  \n",
       "0             0.000000  \n",
       "1            -0.059589  \n",
       "2             0.023889  \n",
       "3            -0.039497  \n",
       "4             0.004223  \n",
       "5            -0.058376  \n",
       "6             0.030563  \n",
       "7            -0.041034  \n",
       "8             0.011421  \n",
       "9            -0.059308  \n",
       "10            0.027807  \n",
       "11           -0.040587  \n",
       "12            0.011717  \n",
       "13           -0.057599  \n",
       "14            0.034294  \n",
       "15           -0.042125  \n",
       "16            0.000584  \n",
       "17           -0.059646  \n",
       "18            0.023862  \n",
       "19           -0.039549  \n",
       "20           -0.001483  \n",
       "21           -0.058431  \n",
       "22            0.030533  \n",
       "23           -0.041076  \n",
       "24            0.011439  \n",
       "25           -0.059361  \n",
       "26            0.027776  \n",
       "27           -0.040631  \n",
       "28            0.011711  \n",
       "29           -0.057647  \n",
       "30            0.034261  \n",
       "31           -0.042155  \n",
       "\n",
       "[32 rows x 27 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mutated_sequences_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d4dfd15-d347-4249-8156-3c2923dcf75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6472cde-c416-4406-bfba-bfd875b0c410",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mutated_sequences_df = pd.read_csv(\"region_scores/enterocytes/SNC_IGFBP2_study/SNC_IGFBP2_study_effects_wcounts.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42467e62-b1a5-4eb8-9942-08112958039b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c194cd30-7c2b-4ecf-9f0b-3584f009354a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='ntot', ylabel='probs_jsd_diff_avg'>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x='ntot',y='probs_jsd_diff_avg',data=all_mutated_sequences_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8a1c341-dfdc-45b9-af0c-c11c64e8f0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mutated_sequences_df_onemut = all_mutated_sequences_df.loc[all_mutated_sequences_df['ntot']<2].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc43b250-2316-4783-9a65-56a85dad6fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mutated_sequences_df_onemut = all_mutated_sequences_df_onemut[['sequence_id', 'ntot', 'SNC','log_counts_diff_avg', 'logcount_preds_avg','log_probs_diff_abs_sum_avg', 'probs_jsd_diff_avg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e514992-466a-44c9-8450-fb857351a3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update 'SNC' column by incrementing the IDs\n",
    "def increment_id(snc):\n",
    "    if isinstance(snc, str) and snc.startswith(\"ID_\"):\n",
    "        id_number = int(snc.split(\"_\")[1])  # Extract the number\n",
    "        return f\"ID_{id_number + 1}\"       # Increment and format back\n",
    "    return snc  # Leave as is if not an ID\n",
    "\n",
    "all_mutated_sequences_df_onemut[\"SNC\"] = all_mutated_sequences_df_onemut[\"SNC\"].apply(increment_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c6abe23-a281-400f-a523-a972c6ab2e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>ntot</th>\n",
       "      <th>SNC</th>\n",
       "      <th>log_counts_diff_avg</th>\n",
       "      <th>logcount_preds_avg</th>\n",
       "      <th>log_probs_diff_abs_sum_avg</th>\n",
       "      <th>probs_jsd_diff_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.651723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ID_5</td>\n",
       "      <td>-0.266680</td>\n",
       "      <td>6.385043</td>\n",
       "      <td>-141.136430</td>\n",
       "      <td>-0.059589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>ID_4</td>\n",
       "      <td>0.090242</td>\n",
       "      <td>6.741964</td>\n",
       "      <td>52.933197</td>\n",
       "      <td>0.023889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>ID_3</td>\n",
       "      <td>0.007536</td>\n",
       "      <td>6.659259</td>\n",
       "      <td>7.298970</td>\n",
       "      <td>0.004223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>ID_2</td>\n",
       "      <td>0.013365</td>\n",
       "      <td>6.665088</td>\n",
       "      <td>11.224241</td>\n",
       "      <td>0.011421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>ID_1</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>6.651866</td>\n",
       "      <td>1.305019</td>\n",
       "      <td>0.000584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sequence_id  ntot   SNC  log_counts_diff_avg  logcount_preds_avg  \\\n",
       "0             0     0   NaN             0.000000            6.651723   \n",
       "1             1     1  ID_5            -0.266680            6.385043   \n",
       "2             2     1  ID_4             0.090242            6.741964   \n",
       "4             4     1  ID_3             0.007536            6.659259   \n",
       "8             8     1  ID_2             0.013365            6.665088   \n",
       "16           16     1  ID_1             0.000143            6.651866   \n",
       "\n",
       "    log_probs_diff_abs_sum_avg  probs_jsd_diff_avg  \n",
       "0                     0.000000            0.000000  \n",
       "1                  -141.136430           -0.059589  \n",
       "2                    52.933197            0.023889  \n",
       "4                     7.298970            0.004223  \n",
       "8                    11.224241            0.011421  \n",
       "16                    1.305019            0.000584  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mutated_sequences_df_onemut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff41c384-40f0-40ce-a647-ac40b886ff03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'sequence_id', 'ntot', 'SNC', 'fold_0--logcount_preds',\n",
       "       'fold_0--log_counts_diff', 'fold_0--log_probs_diff_abs_sum',\n",
       "       'fold_0--probs_jsd_diff', 'fold_1--logcount_preds',\n",
       "       'fold_1--log_counts_diff', 'fold_1--log_probs_diff_abs_sum',\n",
       "       'fold_1--probs_jsd_diff', 'fold_2--logcount_preds',\n",
       "       'fold_2--log_counts_diff', 'fold_2--log_probs_diff_abs_sum',\n",
       "       'fold_2--probs_jsd_diff', 'fold_3--logcount_preds',\n",
       "       'fold_3--log_counts_diff', 'fold_3--log_probs_diff_abs_sum',\n",
       "       'fold_3--probs_jsd_diff', 'fold_4--logcount_preds',\n",
       "       'fold_4--log_counts_diff', 'fold_4--log_probs_diff_abs_sum',\n",
       "       'fold_4--probs_jsd_diff', 'log_counts_diff_avg', 'logcount_preds_avg',\n",
       "       'log_probs_diff_abs_sum_avg', 'probs_jsd_diff_avg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mutated_sequences_df_onemut.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39bfa7cf-7125-4366-8418-f75671850fe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='ntot', ylabel='log_probs_diff_abs_sum_avg'>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x='ntot',y='log_probs_diff_abs_sum_avg',data=all_mutated_sequences_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2b45e1b-355e-40b9-91c5-8415a727b219",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='ntot', ylabel='log_probs_diff_abs_sum_avg'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='ntot',y='log_probs_diff_abs_sum_avg',data=all_mutated_sequences_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b5b40620-bf62-48b0-bee7-298979fe040e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='ntot', ylabel='log_counts_diff_avg'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x='ntot',y='log_counts_diff_avg',data=all_mutated_sequences_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6913fe3f-0a3d-4c7a-9453-03644ca6cdf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29ffbf4-f228-4754-8c91-b8f8780ccf28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca52eff8-b48f-40f8-9208-9bbd58e46136",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SNC_info' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mSNC_info\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_counts_diff\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m log_counts_diff\n\u001b[1;32m      2\u001b[0m SNC_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlog_probs_diff_abs_sum\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m log_probs_diff_abs_sum\n\u001b[1;32m      3\u001b[0m SNC_info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprobs_jsd_diff\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m probs_jsd_diff\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SNC_info' is not defined"
     ]
    }
   ],
   "source": [
    "SNC_info['log_counts_diff'] = log_counts_diff\n",
    "SNC_info['log_probs_diff_abs_sum'] = log_probs_diff_abs_sum\n",
    "SNC_info['probs_jsd_diff'] = probs_jsd_diff\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4dd874c-0138-497b-aae4-8fcdd291b979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>ntot</th>\n",
       "      <th>SNC</th>\n",
       "      <th>fold_0--logcount_preds</th>\n",
       "      <th>fold_0--log_counts_diff</th>\n",
       "      <th>fold_0--log_probs_diff_abs_sum</th>\n",
       "      <th>fold_0--probs_jsd_diff</th>\n",
       "      <th>fold_1--logcount_preds</th>\n",
       "      <th>fold_1--log_counts_diff</th>\n",
       "      <th>fold_1--log_probs_diff_abs_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>fold_3--log_probs_diff_abs_sum</th>\n",
       "      <th>fold_3--probs_jsd_diff</th>\n",
       "      <th>fold_4--logcount_preds</th>\n",
       "      <th>fold_4--log_counts_diff</th>\n",
       "      <th>fold_4--log_probs_diff_abs_sum</th>\n",
       "      <th>fold_4--probs_jsd_diff</th>\n",
       "      <th>log_counts_diff_avg</th>\n",
       "      <th>logcount_preds_avg</th>\n",
       "      <th>log_probs_diff_abs_sum_avg</th>\n",
       "      <th>probs_jsd_diff_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>ID_0</td>\n",
       "      <td>6.834239</td>\n",
       "      <td>0.001013</td>\n",
       "      <td>1.461514</td>\n",
       "      <td>0.000649</td>\n",
       "      <td>6.719839</td>\n",
       "      <td>0.002998</td>\n",
       "      <td>2.456373</td>\n",
       "      <td>...</td>\n",
       "      <td>1.736870</td>\n",
       "      <td>0.000867</td>\n",
       "      <td>6.592869</td>\n",
       "      <td>-0.005172</td>\n",
       "      <td>-1.718345</td>\n",
       "      <td>-0.000708</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>6.651865</td>\n",
       "      <td>1.305019</td>\n",
       "      <td>0.000584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>ID_1</td>\n",
       "      <td>6.839322</td>\n",
       "      <td>0.006096</td>\n",
       "      <td>9.928485</td>\n",
       "      <td>0.012224</td>\n",
       "      <td>6.747108</td>\n",
       "      <td>0.030267</td>\n",
       "      <td>14.280170</td>\n",
       "      <td>...</td>\n",
       "      <td>8.058056</td>\n",
       "      <td>0.010833</td>\n",
       "      <td>6.603245</td>\n",
       "      <td>0.005204</td>\n",
       "      <td>11.884699</td>\n",
       "      <td>0.011219</td>\n",
       "      <td>0.013365</td>\n",
       "      <td>6.665088</td>\n",
       "      <td>11.224241</td>\n",
       "      <td>0.011421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>ID_2</td>\n",
       "      <td>6.869263</td>\n",
       "      <td>0.036038</td>\n",
       "      <td>19.356945</td>\n",
       "      <td>0.013294</td>\n",
       "      <td>6.733350</td>\n",
       "      <td>0.016510</td>\n",
       "      <td>22.509020</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.728277</td>\n",
       "      <td>-0.009528</td>\n",
       "      <td>6.600073</td>\n",
       "      <td>0.002033</td>\n",
       "      <td>17.331200</td>\n",
       "      <td>0.014218</td>\n",
       "      <td>0.007536</td>\n",
       "      <td>6.659259</td>\n",
       "      <td>7.298970</td>\n",
       "      <td>0.004223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>ID_3</td>\n",
       "      <td>6.908408</td>\n",
       "      <td>0.075182</td>\n",
       "      <td>33.376160</td>\n",
       "      <td>0.017666</td>\n",
       "      <td>6.784744</td>\n",
       "      <td>0.067904</td>\n",
       "      <td>42.209888</td>\n",
       "      <td>...</td>\n",
       "      <td>28.959709</td>\n",
       "      <td>0.014956</td>\n",
       "      <td>6.710413</td>\n",
       "      <td>0.112372</td>\n",
       "      <td>59.539883</td>\n",
       "      <td>0.026189</td>\n",
       "      <td>0.090242</td>\n",
       "      <td>6.741964</td>\n",
       "      <td>52.933197</td>\n",
       "      <td>0.023889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ID_4</td>\n",
       "      <td>6.638362</td>\n",
       "      <td>-0.194863</td>\n",
       "      <td>-84.390945</td>\n",
       "      <td>-0.039753</td>\n",
       "      <td>6.548262</td>\n",
       "      <td>-0.168579</td>\n",
       "      <td>-68.829819</td>\n",
       "      <td>...</td>\n",
       "      <td>-229.828857</td>\n",
       "      <td>-0.092687</td>\n",
       "      <td>6.351476</td>\n",
       "      <td>-0.246565</td>\n",
       "      <td>-140.442535</td>\n",
       "      <td>-0.059369</td>\n",
       "      <td>-0.266680</td>\n",
       "      <td>6.385043</td>\n",
       "      <td>-141.136429</td>\n",
       "      <td>-0.059589</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sequence_id  ntot   SNC  fold_0--logcount_preds  fold_0--log_counts_diff  \\\n",
       "16           16     1  ID_0                6.834239                 0.001013   \n",
       "8             8     1  ID_1                6.839322                 0.006096   \n",
       "4             4     1  ID_2                6.869263                 0.036038   \n",
       "2             2     1  ID_3                6.908408                 0.075182   \n",
       "1             1     1  ID_4                6.638362                -0.194863   \n",
       "\n",
       "    fold_0--log_probs_diff_abs_sum  fold_0--probs_jsd_diff  \\\n",
       "16                        1.461514                0.000649   \n",
       "8                         9.928485                0.012224   \n",
       "4                        19.356945                0.013294   \n",
       "2                        33.376160                0.017666   \n",
       "1                       -84.390945               -0.039753   \n",
       "\n",
       "    fold_1--logcount_preds  fold_1--log_counts_diff  \\\n",
       "16                6.719839                 0.002998   \n",
       "8                 6.747108                 0.030267   \n",
       "4                 6.733350                 0.016510   \n",
       "2                 6.784744                 0.067904   \n",
       "1                 6.548262                -0.168579   \n",
       "\n",
       "    fold_1--log_probs_diff_abs_sum  ...  fold_3--log_probs_diff_abs_sum  \\\n",
       "16                        2.456373  ...                        1.736870   \n",
       "8                        14.280170  ...                        8.058056   \n",
       "4                        22.509020  ...                      -10.728277   \n",
       "2                        42.209888  ...                       28.959709   \n",
       "1                       -68.829819  ...                     -229.828857   \n",
       "\n",
       "    fold_3--probs_jsd_diff  fold_4--logcount_preds  fold_4--log_counts_diff  \\\n",
       "16                0.000867                6.592869                -0.005172   \n",
       "8                 0.010833                6.603245                 0.005204   \n",
       "4                -0.009528                6.600073                 0.002033   \n",
       "2                 0.014956                6.710413                 0.112372   \n",
       "1                -0.092687                6.351476                -0.246565   \n",
       "\n",
       "    fold_4--log_probs_diff_abs_sum  fold_4--probs_jsd_diff  \\\n",
       "16                       -1.718345               -0.000708   \n",
       "8                        11.884699                0.011219   \n",
       "4                        17.331200                0.014218   \n",
       "2                        59.539883                0.026189   \n",
       "1                      -140.442535               -0.059369   \n",
       "\n",
       "    log_counts_diff_avg  logcount_preds_avg  log_probs_diff_abs_sum_avg  \\\n",
       "16             0.000143            6.651865                    1.305019   \n",
       "8              0.013365            6.665088                   11.224241   \n",
       "4              0.007536            6.659259                    7.298970   \n",
       "2              0.090242            6.741964                   52.933197   \n",
       "1             -0.266680            6.385043                 -141.136429   \n",
       "\n",
       "    probs_jsd_diff_avg  \n",
       "16            0.000584  \n",
       "8             0.011421  \n",
       "4             0.004223  \n",
       "2             0.023889  \n",
       "1            -0.059589  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mutated_sequences_df.loc[all_mutated_sequences_df['ntot']==1].sort_values(by='SNC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ee9ea2c7-6e41-49d5-8ac9-c3ffb01ee6be",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Could not interpret value `log_counts_diff` for `y`. An entry with this name does not appear in `data`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboxplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mntot\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlog_counts_diff\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mall_mutated_sequences_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/seaborn/categorical.py:1597\u001b[0m, in \u001b[0;36mboxplot\u001b[0;34m(data, x, y, hue, order, hue_order, orient, color, palette, saturation, fill, dodge, width, gap, whis, linecolor, linewidth, fliersize, hue_norm, native_scale, log_scale, formatter, legend, ax, **kwargs)\u001b[0m\n\u001b[1;32m   1589\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mboxplot\u001b[39m(\n\u001b[1;32m   1590\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m, x\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, hue\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, hue_order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1591\u001b[0m     orient\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, palette\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, saturation\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m.75\u001b[39m, fill\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1594\u001b[0m     legend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m, ax\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m   1595\u001b[0m ):\n\u001b[0;32m-> 1597\u001b[0m     p \u001b[38;5;241m=\u001b[39m \u001b[43m_CategoricalPlotter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1598\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1599\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1601\u001b[0m \u001b[43m        \u001b[49m\u001b[43morient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlegend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlegend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1606\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ax \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1607\u001b[0m         ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mgca()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/seaborn/categorical.py:67\u001b[0m, in \u001b[0;36m_CategoricalPlotter.__init__\u001b[0;34m(self, data, variables, order, orient, require_numeric, color, legend)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     58\u001b[0m     data\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m     legend\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mauto\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     65\u001b[0m ):\n\u001b[0;32m---> 67\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# This method takes care of some bookkeeping that is necessary because the\u001b[39;00m\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;66;03m# original categorical plots (prior to the 2021 refactor) had some rules that\u001b[39;00m\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# don't fit exactly into VectorPlotter logic. It may be wise to have a second\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# default VectorPlotter rules. If we do decide to make orient part of the\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;66;03m# _base variable assignment, we'll want to figure out how to express that.\u001b[39;00m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_format \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwide\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m orient \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mh\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/seaborn/_base.py:634\u001b[0m, in \u001b[0;36mVectorPlotter.__init__\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    629\u001b[0m \u001b[38;5;66;03m# var_ordered is relevant only for categorical axis variables, and may\u001b[39;00m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;66;03m# be better handled by an internal axis information object that tracks\u001b[39;00m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;66;03m# such information and is set up by the scale_* methods. The analogous\u001b[39;00m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;66;03m# information for numeric axes would be information about log scales.\u001b[39;00m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_var_ordered \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mFalse\u001b[39;00m}  \u001b[38;5;66;03m# alt., used DefaultDict\u001b[39;00m\n\u001b[0;32m--> 634\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    636\u001b[0m \u001b[38;5;66;03m# TODO Lots of tests assume that these are called to initialize the\u001b[39;00m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;66;03m# mappings to default values on class initialization. I'd prefer to\u001b[39;00m\n\u001b[1;32m    638\u001b[0m \u001b[38;5;66;03m# move away from that and only have a mapping when explicitly called.\u001b[39;00m\n\u001b[1;32m    639\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyle\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/seaborn/_base.py:679\u001b[0m, in \u001b[0;36mVectorPlotter.assign_variables\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;66;03m# When dealing with long-form input, use the newer PlotData\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;66;03m# object (internal but introduced for the objects interface)\u001b[39;00m\n\u001b[1;32m    677\u001b[0m     \u001b[38;5;66;03m# to centralize / standardize data consumption logic.\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_format \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlong\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 679\u001b[0m     plot_data \u001b[38;5;241m=\u001b[39m \u001b[43mPlotData\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    680\u001b[0m     frame \u001b[38;5;241m=\u001b[39m plot_data\u001b[38;5;241m.\u001b[39mframe\n\u001b[1;32m    681\u001b[0m     names \u001b[38;5;241m=\u001b[39m plot_data\u001b[38;5;241m.\u001b[39mnames\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/seaborn/_core/data.py:58\u001b[0m, in \u001b[0;36mPlotData.__init__\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     53\u001b[0m     data: DataSource,\n\u001b[1;32m     54\u001b[0m     variables: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, VariableSpec],\n\u001b[1;32m     55\u001b[0m ):\n\u001b[1;32m     57\u001b[0m     data \u001b[38;5;241m=\u001b[39m handle_data_source(data)\n\u001b[0;32m---> 58\u001b[0m     frame, names, ids \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assign_variables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframe \u001b[38;5;241m=\u001b[39m frame\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnames \u001b[38;5;241m=\u001b[39m names\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/seaborn/_core/data.py:232\u001b[0m, in \u001b[0;36mPlotData._assign_variables\u001b[0;34m(self, data, variables)\u001b[0m\n\u001b[1;32m    230\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    231\u001b[0m         err \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAn entry with this name does not appear in `data`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(err)\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    235\u001b[0m \n\u001b[1;32m    236\u001b[0m     \u001b[38;5;66;03m# Otherwise, assume the value somehow represents data\u001b[39;00m\n\u001b[1;32m    237\u001b[0m \n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# Ignore empty data structures\u001b[39;00m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(val, Sized) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(val) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret value `log_counts_diff` for `y`. An entry with this name does not appear in `data`."
     ]
    }
   ],
   "source": [
    "sns.boxplot(x='ntot',y='log_counts_diff',data=all_mutated_sequences_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "87d4a76e-e8a6-4792-a879-7ff58bcdba4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_mutated_sequences_ohe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "236d5d42-7394-4691-9451-fef4012d1a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2114"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_mutated_sequences_ohe[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cce02a4f-9dbb-437c-b7c7-c161f054a627",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sequence_id</th>\n",
       "      <th>ntot</th>\n",
       "      <th>SNC</th>\n",
       "      <th>fold_0--logcount_preds</th>\n",
       "      <th>fold_0--log_counts_diff</th>\n",
       "      <th>fold_0--log_probs_diff_abs_sum</th>\n",
       "      <th>fold_0--probs_jsd_diff</th>\n",
       "      <th>fold_1--logcount_preds</th>\n",
       "      <th>fold_1--log_counts_diff</th>\n",
       "      <th>fold_1--log_probs_diff_abs_sum</th>\n",
       "      <th>...</th>\n",
       "      <th>fold_3--log_probs_diff_abs_sum</th>\n",
       "      <th>fold_3--probs_jsd_diff</th>\n",
       "      <th>fold_4--logcount_preds</th>\n",
       "      <th>fold_4--log_counts_diff</th>\n",
       "      <th>fold_4--log_probs_diff_abs_sum</th>\n",
       "      <th>fold_4--probs_jsd_diff</th>\n",
       "      <th>log_counts_diff_avg</th>\n",
       "      <th>logcount_preds_avg</th>\n",
       "      <th>log_probs_diff_abs_sum_avg</th>\n",
       "      <th>probs_jsd_diff_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>6.833225</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.716840</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.598041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.651723</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>ID_0_ID_1_ID_2_ID_3_ID_4</td>\n",
       "      <td>6.763645</td>\n",
       "      <td>-0.06958</td>\n",
       "      <td>-40.867828</td>\n",
       "      <td>-0.027115</td>\n",
       "      <td>6.653368</td>\n",
       "      <td>-0.063472</td>\n",
       "      <td>-30.300707</td>\n",
       "      <td>...</td>\n",
       "      <td>-203.545898</td>\n",
       "      <td>-0.083289</td>\n",
       "      <td>6.483650</td>\n",
       "      <td>-0.114391</td>\n",
       "      <td>-52.546257</td>\n",
       "      <td>-0.030085</td>\n",
       "      <td>-0.164755</td>\n",
       "      <td>6.486968</td>\n",
       "      <td>-84.358963</td>\n",
       "      <td>-0.042155</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    sequence_id  ntot                       SNC  fold_0--logcount_preds  \\\n",
       "0             0     0                                          6.833225   \n",
       "31           31     5  ID_0_ID_1_ID_2_ID_3_ID_4                6.763645   \n",
       "\n",
       "    fold_0--log_counts_diff  fold_0--log_probs_diff_abs_sum  \\\n",
       "0                   0.00000                        0.000000   \n",
       "31                 -0.06958                      -40.867828   \n",
       "\n",
       "    fold_0--probs_jsd_diff  fold_1--logcount_preds  fold_1--log_counts_diff  \\\n",
       "0                 0.000000                6.716840                 0.000000   \n",
       "31               -0.027115                6.653368                -0.063472   \n",
       "\n",
       "    fold_1--log_probs_diff_abs_sum  ...  fold_3--log_probs_diff_abs_sum  \\\n",
       "0                         0.000000  ...                        0.000000   \n",
       "31                      -30.300707  ...                     -203.545898   \n",
       "\n",
       "    fold_3--probs_jsd_diff  fold_4--logcount_preds  fold_4--log_counts_diff  \\\n",
       "0                 0.000000                6.598041                 0.000000   \n",
       "31               -0.083289                6.483650                -0.114391   \n",
       "\n",
       "    fold_4--log_probs_diff_abs_sum  fold_4--probs_jsd_diff  \\\n",
       "0                         0.000000                0.000000   \n",
       "31                      -52.546257               -0.030085   \n",
       "\n",
       "    log_counts_diff_avg  logcount_preds_avg  log_probs_diff_abs_sum_avg  \\\n",
       "0              0.000000            6.651723                    0.000000   \n",
       "31            -0.164755            6.486968                  -84.358963   \n",
       "\n",
       "    probs_jsd_diff_avg  \n",
       "0             0.000000  \n",
       "31           -0.042155  \n",
       "\n",
       "[2 rows x 27 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_mutated_sequences_df.loc[all_mutated_sequences_df['ntot'].isin([0,5])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6207f680-315d-4e7a-bee3-1d1f70fbd15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_mutated_sequences_ohe_extremes = np.array([all_mutated_sequences_ohe[0],all_mutated_sequences_ohe[31]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "966e661f-b78a-4c43-8187-1d26d4b23cf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "190"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Reset TensorFlow session\n",
    "tf.keras.backend.clear_session()\n",
    "import torch\n",
    "\n",
    "# If using PyTorch:\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Optional: Explicit garbage collection\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a7dc25a-5fdd-469f-8cfb-b131393b5951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2114, 4)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(all_mutated_sequences_ohe_extremes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7fa3f78d-2530-4acd-9568-4f14dcb74cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c6cebb11-0c67-4d36-aa17-5bb1d39a3107",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold_0\n",
      "WARNING:tensorflow:OMP_NUM_THREADS is no longer used by the default Keras config. To configure the number of threads, use tf.config.threading APIs.\n",
      "got the model\n",
      "Seqs dimension : (2, 2114, 4)\n",
      "WARNING:tensorflow:From /cluster/home/jjanssens/.local/lib/python3.10/site-packages/shap/explainers/deep/deep_tf.py:140: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Generating 'counts' shap scores\n",
      "Done 0 examples of 2\n",
      "Saving 'counts' scores\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  StopGradient used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Generating 'profile' shap scores\n",
      "Done 0 examples of 2\n",
      "Saving 'profile' scores\n",
      "fold_1\n",
      "got the model\n",
      "Seqs dimension : (2, 2114, 4)\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Generating 'counts' shap scores\n",
      "Done 0 examples of 2\n",
      "Saving 'counts' scores\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  StopGradient used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Generating 'profile' shap scores\n",
      "Done 0 examples of 2\n",
      "Saving 'profile' scores\n",
      "fold_2\n",
      "got the model\n",
      "Seqs dimension : (2, 2114, 4)\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Generating 'counts' shap scores\n",
      "Done 0 examples of 2\n",
      "Saving 'counts' scores\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  StopGradient used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Generating 'profile' shap scores\n",
      "Done 0 examples of 2\n",
      "Saving 'profile' scores\n",
      "fold_3\n",
      "got the model\n",
      "Seqs dimension : (2, 2114, 4)\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Generating 'counts' shap scores\n",
      "Done 0 examples of 2\n",
      "Saving 'counts' scores\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  StopGradient used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Generating 'profile' shap scores\n",
      "Done 0 examples of 2\n",
      "Saving 'profile' scores\n",
      "fold_4\n",
      "got the model\n",
      "Seqs dimension : (2, 2114, 4)\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Generating 'counts' shap scores\n",
      "Done 0 examples of 2\n",
      "Saving 'counts' scores\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  AddV2 used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  StopGradient used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  SpaceToBatchND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Warning:  BatchToSpaceND used in model but handling of op is not specified by shap; will use original  gradients\n",
      "Generating 'profile' shap scores\n",
      "Done 0 examples of 2\n",
      "Saving 'profile' scores\n"
     ]
    }
   ],
   "source": [
    "for fold in ['fold_0','fold_1','fold_2','fold_3','fold_4']:\n",
    "    print(fold)\n",
    "    model_path = 'celltype_models_human/modelv1_enterocytes/'+fold+'/output/models/chrombpnet_nobias.h5'\n",
    "    \n",
    "    custom_objects={\"multinomial_nll\": losses.multinomial_nll, \"tf\": tf}    \n",
    "    get_custom_objects().update(custom_objects)    \n",
    "    model=load_model(model_path,compile=False)\n",
    "    print(\"got the model\")\n",
    "\n",
    "    results = interpret(model, all_mutated_sequences_ohe_extremes, 'SNC_IGFBP2_study_extr_'+fold, ['profile','counts'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfc8c62-0c3c-4147-8358-d61d83b9c400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a24075-08a0-4d0a-acd3-1bb5b87390c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d82fef11-8e49-4539-916c-3feca1a04f89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e369e12-9aa7-466d-b491-29289f8b2960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chrompbnet2",
   "language": "python",
   "name": "chrombpnet2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
